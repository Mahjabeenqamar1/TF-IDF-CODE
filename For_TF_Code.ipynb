{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "For TF Code",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahjabeenqamar1/TF-IDF-CODE/blob/main/For_TF_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Wws7_pj_Sr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "ce4271a7-8352-4197-bd87-6a206fdb9254"
      },
      "source": [
        "%tensorflow_version 2.2\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab import files\n",
        "import time\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import random\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.2`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xVf687JkE2R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45d477b6-41cc-49fa-83a2-1a533d583466"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUvAEv3DkGXt"
      },
      "source": [
        "def load(img_path):\n",
        "    return np.load(img_path, allow_pickle=True)\n",
        "\n",
        "def create_ID_dict(basepath):\n",
        "  dictionary = {}\n",
        "  mask_list =[]\n",
        "  image_list =[]\n",
        "\n",
        "  for file in glob.glob(basepath+'/**/**.npy', recursive=True):\n",
        "    if 'r.npy' in file:\n",
        "      mask_list.append(file)\n",
        "    elif 'cti.npy' in file:\n",
        "      image_list.append(file)\n",
        "\n",
        "  \n",
        "  dictionary.update({\"image\":image_list})\n",
        "  dictionary.update({\"mask\":mask_list})\n",
        "  return dictionary\n",
        "\n",
        "\n",
        "'''class ImageSequence(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "    \n",
        "        self.dictionary = {}\n",
        "        mask_list =[]\n",
        "        image_list =[]\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        basepath = '/content/drive/My Drive/Sample_Data_for_TF/trv1_p1'\n",
        "\n",
        "        for file in glob.glob(basepath+'/**/**.npy', recursive=True):\n",
        "            if 'r.npy' in file:\n",
        "                mask_list.append(file)\n",
        "            elif 'cti.npy' in file:\n",
        "                image_list.append(file)\n",
        "\n",
        "  \n",
        "        self.dictionary[\"image\"] = image_list\n",
        "        self.dictionary[\"mask\"] = mask_list\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.dictionary[\"image\"]) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.dictionary[\"image\"][idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "        batch_y = self.dictionary[\"mask\"][idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "\n",
        "\n",
        "        return np.array([load(file_name)[random.randrange(0,50)].reshape(1,512,512) for file_name in batch_x]), \n",
        "        np.array([load(file_name)[random.randrange(0,50)].reshape(1,512,512) for file_name in batch_y])'''\n",
        "\n",
        "\n",
        "def dataset_gen(dictionary, mask):\n",
        "  image_list= [] \n",
        "  mask_list = []\n",
        " \n",
        "\n",
        "  if mask == True:\n",
        "    n = 0\n",
        "\n",
        "    for path0, path1 in zip(dictionary['image'],dictionary['mask']):\n",
        "      image0 = load(path0)\n",
        "     # print(\"{} loaded\".format(path0))\n",
        "      image1 = load(path1) #preprocessing has happened befoer hand\n",
        "     # print(\"{} loaded\".format(path1))\n",
        "      \n",
        "      for slice0, slice1 in zip(image0,image1):\n",
        "        #print(\"in slice loop\")\n",
        "\n",
        "        slice0= np.reshape(slice0,(1,512,512))\n",
        "        slice0 = slice0.astype('float32')\n",
        "        print(\"slice0 shape: \", slice0.shape)\n",
        "\n",
        "        slice1= np.reshape(slice1,(1,512,512))\n",
        "        slice1= slice1.astype('float32')\n",
        "        print(\"slice1 shape: \", slice1.shape)\n",
        "        \n",
        "        image_list.append(slice0)\n",
        "        mask_list.append(slice1)\n",
        "       \n",
        "\n",
        "      n+=1\n",
        "      print(\"{} images have been loaded.\".format(str(n)+'/'+str(len(dictionary['image']))))\n",
        "    \n",
        "    return image_list, mask_list\n",
        "  else:\n",
        "    print(\"option not possible yet\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he-fVbQHk7FZ"
      },
      "source": [
        "'''Predetermined Variables'''\n",
        "PATH_tr = '/content/drive/My Drive/Sample_Data_for_TF/trv1_p1'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35JpldeElBgj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf2610f2-eb2f-451a-d39b-12789e52a453"
      },
      "source": [
        "''' Loading Data Sets '''\n",
        "print(\"loading datasets\")\n",
        "\n",
        "start_time = time.time()\n",
        "tr_dict = create_ID_dict(PATH_tr)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Dictionary Creation Took {} seconds\".format(end_time-start_time))\n",
        "\n",
        "start_time = time.time()\n",
        "image_list, mask_list = dataset_gen(tr_dict,mask = True)\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "print(\"Generators Creation Took {} sec\".format(end_time-start_time))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading datasets\n",
            "Dictionary Creation Took 0.0014197826385498047 seconds\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "slice0 shape:  (1, 512, 512)\n",
            "slice1 shape:  (1, 512, 512)\n",
            "1/1 images have been loaded.\n",
            "Generators Creation Took 0.3903350830078125 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax6LnIHelG8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "1153221e-882e-4566-a297-23cf2735cc40"
      },
      "source": [
        "'''Model Creation'''\n",
        "tf.executing_eagerly()\n",
        "#Define model#\n",
        "# Define kwargs dictionary#\n",
        "kwargs = {\n",
        "  'kernel_size': (3,3),\n",
        "  'padding': 'same',\n",
        "  'data_format': 'channels_first'}\n",
        "\n",
        "#Define lambda functions#\n",
        "conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.LeakyReLU()(x)\n",
        "\n",
        "#Define stride-1, stride-2 blocks#\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=2)))\n",
        "\n",
        "#Define single transpose#\n",
        "tran = lambda x, filters, strides : layers.Conv2DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "\n",
        "#Define transpose block#\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=2)))\n",
        "concat = lambda a, b : layers.Concatenate(axis=1)([a, b])\n",
        "\n",
        "#Define Dense Block#\n",
        "def dense_block(filters,input):\n",
        "  l1 = conv1(filters, input)\n",
        "  c1 = concat(input,l1)\n",
        "  l2 = conv1(filters,c1)\n",
        "  c2 = concat(c1,l2)\n",
        "  l3 = conv1(filters, c2)\n",
        "  c3 = concat(c2,l3)\n",
        "  l4 = conv1(filters,c3)\n",
        "\n",
        "  return concat(input,l4)\n",
        "\n",
        "def td_block(conv1_filters,conv2_filters,input):\n",
        "  TD = conv1(conv1_filters,conv2(conv2_filters,input))\n",
        "  print(\"TD Shape = \", TD.shape)\n",
        "  DB = dense_block(conv1_filters,TD)\n",
        "  print(\"Dense Block Shape: \", DB.shape)\n",
        "  return DB\n",
        "\n",
        "def tu_block(conv1_filters,tran2_filters,input,td_input):\n",
        "  TU = conv1(conv1_filters,tran2(tran2_filters,input))\n",
        "  print(\"TU Shape: \", TU.shape)\n",
        "  C = concat(TU,td_input)\n",
        "  print(\"C Shape: \", C.shape)\n",
        "  DB = dense_block(conv1_filters,C)\n",
        "  print(\"Dense Block Shape: \", DB.shape)\n",
        "  return DB\n",
        "\n",
        "#Build Model#\n",
        "# TD = convolutions that train down, DB = Dense blocks, TU = Transpose convolutions that train up, C = concatenation groups.\n",
        "\n",
        "inputs = Input(shape=(1,512,512))\n",
        "print(\"Input Shape: \", inputs.shape)\n",
        "TD1 = conv2(18,inputs) #basic convolution of stride 2, no maxpool.\n",
        "print(\"TD Shape: \", TD1.shape)\n",
        "DB1 = dense_block(18,TD1)\n",
        "print(\"Dense Block Shape: \",DB1.shape )\n",
        "\n",
        "TD2 = td_block(32,18, DB1)\n",
        "TD3 = td_block(64,32,TD2)\n",
        "TD4 = td_block(86,64,TD3)\n",
        "TD5 = td_block(126,86,TD4)\n",
        "print(\"TD5 shape: \", TD5.shape)\n",
        "\n",
        "TU1 = tu_block(86,126,TD5,TD4)\n",
        "TU2 = tu_block(64,86,TU1,TD3)\n",
        "TU3 = tu_block(32,64,TU2,TD2)\n",
        "TU4 = tu_block(18,32,TU3,TD1)\n",
        "TU5 = tran2(1, TU4)\n",
        "\n",
        "\n",
        "logits = layers.Conv2D(filters = 1, **kwargs)(TU5)\n",
        "print(logits.shape)\n",
        "model = Model(inputs=inputs, outputs=logits )\n",
        "\n",
        "\n",
        "optimizer = \"adam\"\n",
        "loss = \"categorical_crossentropy\"\n",
        "metrics = ['accuracy']\n",
        "model.compile(optimizer= optimizer,loss = loss, metrics =metrics)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Shape:  (None, 1, 512, 512)\n",
            "TD Shape:  (None, 18, 256, 256)\n",
            "Dense Block Shape:  (None, 36, 256, 256)\n",
            "TD Shape =  (None, 32, 128, 128)\n",
            "Dense Block Shape:  (None, 64, 128, 128)\n",
            "TD Shape =  (None, 64, 64, 64)\n",
            "Dense Block Shape:  (None, 128, 64, 64)\n",
            "TD Shape =  (None, 86, 32, 32)\n",
            "Dense Block Shape:  (None, 172, 32, 32)\n",
            "TD Shape =  (None, 126, 16, 16)\n",
            "Dense Block Shape:  (None, 252, 16, 16)\n",
            "TD5 shape:  (None, 252, 16, 16)\n",
            "TU Shape:  (None, 86, 32, 32)\n",
            "C Shape:  (None, 258, 32, 32)\n",
            "Dense Block Shape:  (None, 344, 32, 32)\n",
            "TU Shape:  (None, 64, 64, 64)\n",
            "C Shape:  (None, 192, 64, 64)\n",
            "Dense Block Shape:  (None, 256, 64, 64)\n",
            "TU Shape:  (None, 32, 128, 128)\n",
            "C Shape:  (None, 96, 128, 128)\n",
            "Dense Block Shape:  (None, 128, 128, 128)\n",
            "TU Shape:  (None, 18, 256, 256)\n",
            "C Shape:  (None, 36, 256, 256)\n",
            "Dense Block Shape:  (None, 54, 256, 256)\n",
            "(None, 1, 512, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hqqotuCMGG0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "e2c11213-2a40-4144-bca7-aa0bbec1ab3f"
      },
      "source": [
        "image_list = tf.convert_to_tensor(image_list)\n",
        "mask_list = tf.convert_to_tensor(mask_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9959f1f0b9ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmask_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class DatasetV2 with abstract methods _inputs, element_spec"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw9XdImulHsT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "84ca9565-53e1-494c-cb45-c7fa499301c5"
      },
      "source": [
        "#obj= ImageSequence(None, None,1)\n",
        "model.fit(image_list,mask_list, epochs=1, batch_size=20 )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 764ms/step - loss: 0.0000e+00 - accuracy: 0.0015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa813c134e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}